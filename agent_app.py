# -*- coding: utf-8 -*-
"""agent_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12twTZo21rff-6vHoRDoWKO_lTGBJOJXr
"""

import streamlit as st
import os
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter # Uso questo come da tuo codice
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.tools import tool
from langchain_core.prompts import PromptTemplate
from langchain_classic.agents import create_react_agent, AgentExecutor

# --- FUNZIONE DI CACHING PER IL SETUP DELL'AGENTE ---
#
# Questo decoratore @st.cache_resource è FONDAMENTALE.
# Dice a Streamlit di eseguire questa funzione solo la PRIMA volta che l'app carica.
# Caricherà l'LLM, il modello di embedding (che è pesante!), il file .txt
# e costruirà l'agente. Il risultato (l'agent_executor)
# viene "salvato" in memoria per essere riutilizzato velocemente.
#
@st.cache_resource
def get_agent_executor():
    # --- 1. Caricamento API Key (Modo Streamlit) ---
    try:
        GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
    except KeyError:
        st.error("ERRORE: GOOGLE_API_KEY non trovato.")
        st.info("Aggiungi la tua chiave API nei 'Secrets' delle impostazioni dell'app Streamlit.")
        st.stop() # Ferma l'esecuzione se la chiave manca

    # --- 2. Inizializzazione LLM (Gemini) ---
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash",
                                 google_api_key=GOOGLE_API_KEY,
                                 temperature=0.1,
                                 max_output_tokens=2000,
                                 convert_system_message_to_human=True)

    # --- 3. Caricamento Documenti (Modo Streamlit) ---
    # Usiamo un percorso relativo. "regole.txt" deve essere nel repository GitHub.
    try:
        loader = TextLoader("regole.txt")
        documents = loader.load()
    except Exception as e:
        st.error(f"Errore nel caricamento del file 'regole.txt': {e}")
        st.info("Assicurati che 'regole.txt' sia presente nel tuo repository GitHub.")
        st.stop()

    # --- 4. Splitter e Embeddings (HuggingFace) ---
    # Questa parte è pesante e beneficia enormemente della cache

    st.info("Caricamento modello di embedding (richiede qualche istante la prima volta)...")

    text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    docs = text_splitter.split_documents(documents)

    # Carica il modello di embedding italiano
    model_name = "nickprock/sentence-bert-base-italian-xxl-uncased"
    embeddings = HuggingFaceEmbeddings(model_name=model_name)

    # Crea il vector store
    vectordb = Chroma.from_documents(documents=docs, embedding=embeddings)
    retriever = vectordb.as_retriever(search_kwargs={"k": 4})

    st.success("Modello e regole caricati con successo!")


    # --- 5. Definizione del Tool ---
    # Definiamo il tool qui dentro, così ha accesso al 'retriever'
    @tool
    def cerca_regole_semplificazione(argomento):
        """
        Cerca nella base di conoscenza le regole e i consigli
        per un argomento di semplificazione linguistica specifico.
        Usa questo strumento per trovare la regola esatta DOPO
        aver identificato un problema nel testo.
        Esempi di argomenti: 'regola per forma passiva',
        'consigli per frasi lunghe', 'definizione di gergo burocratico'.
        """
        docs_tool = retriever.invoke(argomento)
        return "\n\n".join(doc.page_content for doc in docs_tool)

    tools = [cerca_regole_semplificazione]

    # --- 6. Creazione del Prompt e dell'Agente ---
    AGENT_PROMPT_TEMPLATE = """
    Sei un consulente esperto in semplificazione del linguaggio amministrativo.
    Analizza il testo fornito e fornisci un'analisi sintetica, ragionata e strutturata.

    OBIETTIVO:
    - Identificare le principali CATEGORIE di problemi linguistici (livello alto).
    - Per ciascuna categoria, mostrare esempi specifici tratti dal testo e fornire la regola o il consiglio corrispondente.
    - Non elencare ogni singola criticità minore. Raggruppa i casi simili sotto la stessa categoria.
    - L’obiettivo è una risposta compatta e utile alla revisione del testo.

    STRUMENTI DISPONIBILI:
    {tools}
    (Puoi usare uno dei seguenti strumenti: {tool_names})

    FORMATO PER CHIAMARE GLI STRUMENTI:
    Step: [Breve motivazione, max 10 parole]
    Action: [nome_strumento]
    Action Input: ["query sintetica, es. regola per frasi lunghe"]
    Observation: [attendi il risultato dallo strumento]

    LINEA GUIDA (approccio top-down):
    1. Leggi il testo e individua le principali categorie di criticità linguistiche generali.
    2. Per ogni categoria, usa lo strumento `cerca_regole_semplificazione` per trovare la regola o il consiglio corrispondente.
    3. Collega alla categoria solo alcuni esempi rappresentativi dal testo (non tutti).
    4. Alla fine, sintetizza le categorie e i consigli in una risposta finale chiara e breve.

    OUTPUT FINALE (obbligatorio):
    Final Answer:
    Ecco un riepilogo delle principali aree di miglioramento del testo:

    **Categoria 1: [Nome del problema generale]**
    * **Descrizione:** [Spiega la natura del problema e il principio di semplificazione]
    * **Esempi nel testo:** [2-3 esempi rappresentativi]
    * **Regola/Consiglio:** [Sintesi della regola o del consiglio pratico]

    **Categoria 2: [Altro problema generale]**
    ...

    IMPORTANTE:
    - Non elencare ogni singolo errore.
    - Raggruppa le osservazioni in poche categorie significative.
    - La risposta finale deve iniziare con "Final Answer:" e terminare subito dopo l'elenco.
    - Nessun saluto o testo aggiuntivo dopo la risposta finale.

    Inizia ora!

    Testo da analizzare:
    {input}
    Traccia delle azioni e osservazioni passate:
    {agent_scratchpad}
    """

    agent_prompt = PromptTemplate.from_template(AGENT_PROMPT_TEMPLATE)

    agent = create_react_agent(
        llm=llm,
        tools=tools,
        prompt=agent_prompt
    )

    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=False, # Imposta True se vuoi debuggare il "pensiero" dell'agente
        handle_parsing_errors=True,
        max_iterations=10
    )

    # La funzione restituisce l'esecutore pronto all'uso
    return agent_executor

# --- INTERFACCIA UTENTE (UI) DI STREAMLIT ---

st.title("Agente di Semplificazione")
st.markdown("Questo agente analizza un testo amministrativo e identifica le aree di miglioramento, suggerendo le regole di semplificazione pertinenti.")

# Prova a caricare l'agente (usando la cache)
# Questo mostrerà i messaggi st.info/st.success la prima volta
try:
    agent_executor = get_agent_executor()
except Exception as e:
    st.error(f"Errore critico durante l'inizializzazione dell'agente: {e}")
    st.stop()

# Area di testo per l'input dell'utente
testo_da_analizzare = st.text_area("Incolla qui il testo da analizzare:", height=250,
                                 placeholder="Es: 'Con la presente si notifica che l'adunanza avrà luogo in data odierna...'")

# Bottone per avviare l'elaborazione
if st.button("Analizza Testo"):
    if testo_da_analizzare:
        # Mostra uno "spinner" (rotellina) mentre l'agente lavora
        with st.spinner("L'agente sta pensando... (potrebbe impiegare fino a 30 secondi)"):
            try:
                # --- Invocazione dell'Agente ---
                # L'input deve essere un dizionario con la chiave "input"
                result = agent_executor.invoke({"input": testo_da_analizzare})

                # Mostra il risultato (che è già formattato in Markdown dal prompt)
                st.markdown(result['output'])

            except Exception as e:
                st.error(f"Si è verificato un errore durante l'esecuzione dell'agente: {e}")
    else:
        st.warning("Per favore, inserisci del testo nella casella qui sopra.")